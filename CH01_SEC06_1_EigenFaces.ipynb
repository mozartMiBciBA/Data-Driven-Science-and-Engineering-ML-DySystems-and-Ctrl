{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrXVeHL0azQiEWv5PGFJB1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mozartMiBciBA/Data-Driven-Science-and-Engineering-ML-DySystems-and-Ctrl/blob/main/CH01_SEC06_1_EigenFaces.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This video describes how the singular value decomposition (SVD) can be used to efficiently represent human faces, in the so-called \"eigenfaces\" (Python code, part 1\n",
        "\n",
        "Fuente: https://www.youtube.com/watch?v=ofWji_wQBEE&list=PLMrJAkhIeNNSVjnsviglFoY2nXildDCcv&index=32\n",
        "\n"
      ],
      "metadata": {
        "id": "UV_dNAk0a1xR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMOXd6sMav7p"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import scipy.io\n",
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "#mat_contents = scipy.io.loadmat(os.path.join('..','DATA','allFaces.mat'))\n",
        "\n",
        "mat_contents = scipy.io.loadmat(os.path.join('allFaces.mat'))\n",
        "\n",
        "print(\"mat_contents['']\")\n",
        "print(mat_contents['__header__'])\n",
        "\n",
        "faces = mat_contents['faces']\n",
        "m = int(mat_contents['m'])\n",
        "print(m)\n",
        "\n",
        "n = int(mat_contents['n'])\n",
        "nfaces = np.ndarray.flatten(mat_contents['nfaces'])\n",
        "\n",
        "allPersons = np.zeros((n*6,m*6))\n",
        "count = 0\n",
        "\n",
        "for j in range(6):\n",
        "    for k in range(6):\n",
        "        allPersons[j*n : (j+1)*n, k*m : (k+1)*m] = np.reshape(faces[:,np.sum(nfaces[:count])],(m,n)).T\n",
        "        count += 1\n",
        "        \n",
        "img = plt.imshow(allPersons)\n",
        "img.set_cmap('gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for person in range(len(nfaces)):\n",
        "    subset = faces[:,sum(nfaces[:person]) : sum(nfaces[:(person+1)])]\n",
        "    allFaces = np.zeros((n*8,m*8))\n",
        "    \n",
        "    count = 0\n",
        "    \n",
        "    for j in range(8):\n",
        "        for k in range(8):\n",
        "            if count < nfaces[person]:\n",
        "                allFaces[j*n:(j+1)*n,k*m:(k+1)*m] = np.reshape(subset[:,count],(m,n)).T\n",
        "                count += 1\n",
        "                \n",
        "    img = plt.imshow(allFaces)\n",
        "    img.set_cmap('gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4MuWhbD-CacK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}